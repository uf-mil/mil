#!/usr/bin/env python3
import numpy as np
import rospy
import tf2_ros
from geometry_msgs.msg import Point, PointStamped
from image_geometry import PinholeCameraModel
from mil_msgs.msg import ObjectInImage, ObjectsInImage, PerceptionObject
from mil_msgs.srv import ObjectDBQuery, ObjectDBQueryRequest
from mil_tools import rosmsg_to_numpy
from sensor_msgs.msg import CameraInfo
from tf2_geometry_msgs import do_transform_point


class BBOXPCODAR:
    cached_objects: dict[int, Point]

    def __init__(self):
        self.max_distance = 20.0
        self.camera_model = None
        self.confidence_thresh = 0.0
        self.camera_info_sub = rospy.Subscriber(
            "/camera/front/right/camera_info",
            CameraInfo,
            self.camera_info_cb,
            queue_size=1,
        )
        self.tf_buffer = tf2_ros.Buffer(cache_time=rospy.Duration(30))
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer)
        self.cached_objects = {}
        self.pcodar_client = rospy.ServiceProxy("/database/requests", ObjectDBQuery)
        self.bbox_sub = rospy.Subscriber("/bbox_pub", ObjectsInImage, self.new_objects)
        self.update_objects_timer = rospy.Timer(
            rospy.Duration(10.0), self.update_pcodar_objects
        )

    def camera_info_cb(self, info: CameraInfo) -> None:
        if self.camera_model is not None:
            return
        self.camera_model = PinholeCameraModel()
        self.camera_model.fromCameraInfo(info)
        rospy.loginfo("Got camera info")

    def update_pcodar_objects(self, _: rospy.timer.TimerEvent):
        req = ObjectDBQueryRequest(name="all")
        res = self.pcodar_client(req)
        objects: list[PerceptionObject] = res.objects
        for obj in objects:
            self.cached_objects[obj.id] = obj.pose.position
        rospy.loginfo("Updated objects.")

    @staticmethod
    def point_in_bbox(point: tuple[float, float], bbox: np.ndarray) -> bool:
        return (
            point[0] > bbox[0][0]
            and point[0] < bbox[1][0]
            and point[1] > bbox[0][1]
            and point[1] < bbox[1][1]
        )

    def new_objects(self, msg: ObjectsInImage) -> None:
        if self.camera_model is None:
            return
        # Get transform from enu to camera currently
        try:
            transform = self.tf_buffer.lookup_transform(
                msg.header.frame_id,
                "enu",
                msg.header.stamp,
                timeout=rospy.Duration(
                    3,
                ),
            )
        except tf2_ros.TransformException as e:
            rospy.logwarn(e)
            return
        for idn, point in self.cached_objects.items():
            ps = PointStamped()
            ps.point = point
            ps.header.frame_id = "enu"
            ps.header.stamp = msg.header.stamp

            ps_camera = do_transform_point(ps, transform)

            object_pose_camera = rosmsg_to_numpy(ps_camera.point)

            if np.linalg.norm(object_pose_camera) > self.max_distance:
                continue

            object_pixel: tuple[float, float] = self.camera_model.project3dToPixel(
                object_pose_camera
            )

            rospy.loginfo(f"Object {idn} at pixel {object_pixel}")
            objects: list[ObjectInImage] = msg.objects or []

            for obj in objects:
                points = rosmsg_to_numpy(obj.points)

                if self.point_in_bbox(object_pixel, points):
                    rospy.loginfo(f"{obj.name} found for {idn}")
                    req = ObjectDBQueryRequest()
                    req.cmd = f"{idn}={obj.name}"
                    self.pcodar_client(req)


if __name__ == "__main__":
    rospy.init_node("bbox_pcodar")
    b = BBOXPCODAR()
    rospy.spin()
